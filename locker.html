<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Secure Locker App</title>
    <style>
        body { font-family: Arial, sans-serif; text-align: center; margin: 20px; }
        #video, #canvas { border: 1px solid #ccc; margin: 10px; }
        .step { margin: 20px; padding: 10px; border: 1px solid #ddd; }
        .locked { display: block; }
        .unlocked { display: none; }
        #locker { display: none; background: #f0f0f0; padding: 20px; margin: 20px; }
    </style>
</head>
<body>
    <h1>Secure Locker with Multi-Level Authentication</h1>
    <div id="auth" class="locked">
        <div class="step" id="faceStep">
            <h2>Step 1: Face Lock</h2>
            <video id="video" width="320" height="240" autoplay muted></video>
            <canvas id="canvas" width="320" height="240"></canvas>
            <br>
            <button id="captureFace">Capture Reference Face</button>
            <button id="verifyFace">Verify Face</button>
            <p id="faceStatus"></p>
        </div>
        <div class="step" id="eyeStep" style="display:none;">
            <h2>Step 2: Eye Scan</h2>
            <p>Look directly at the camera for eye scan.</p>
            <button id="scanEye">Scan Eyes</button>
            <p id="eyeStatus"></p>
        </div>
        <div class="step" id="voiceStep" style="display:none;">
            <h2>Step 3: Voice Access</h2>
            <p>Say the passphrase: "Open sesame"</p>
            <button id="startVoice">Start Voice Recognition</button>
            <p id="voiceStatus"></p>
        </div>
    </div>
    <div id="locker">
        <h2>Locker Unlocked!</h2>
        <p>Stored Files:</p>
        <ul>
            <li>Photo1.jpg</li>
            <li>Document.pdf</li>
            <li>App.apk</li>
        </ul>
        <p>Simulated storage - in a real app, files would be encrypted and stored securely.</p>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
        // Variables
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let referenceDescriptor = null;
        let passphrase = "open sesame";

        // Load models
        async function loadModels() {
            await faceapi.loadSsdMobilenetv1Model('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/');
            await faceapi.loadFaceLandmarkModel('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/');
            await faceapi.loadFaceRecognitionModel('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/');
        }

        // Start video
        async function startVideo() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
            } catch (err) {
                alert('Camera access denied.');
            }
        }

        // Face capture
        document.getElementById('captureFace').addEventListener('click', async () => {
            const detection = await faceapi.detectSingleFace(video).withFaceLandmarks().withFaceDescriptor();
            if (detection) {
                referenceDescriptor = detection.descriptor;
                localStorage.setItem('faceDescriptor', JSON.stringify(Array.from(referenceDescriptor)));
                document.getElementById('faceStatus').textContent = 'Reference face captured!';
            } else {
                document.getElementById('faceStatus').textContent = 'No face detected.';
            }
        });

        // Face verify
        document.getElementById('verifyFace').addEventListener('click', async () => {
            if (!referenceDescriptor) {
                const stored = localStorage.getItem('faceDescriptor');
                if (stored) referenceDescriptor = new Float32Array(JSON.parse(stored));
            }
            if (!referenceDescriptor) {
                document.getElementById('faceStatus').textContent = 'No reference face set.';
                return;
            }
            const detection = await faceapi.detectSingleFace(video).withFaceLandmarks().withFaceDescriptor();
            if (detection) {
                const distance = faceapi.euclideanDistance(detection.descriptor, referenceDescriptor);
                if (distance < 0.6) {
                    document.getElementById('faceStatus').textContent = 'Face verified!';
                    document.getElementById('faceStep').style.display = 'none';
                    document.getElementById('eyeStep').style.display = 'block';
                } else {
                    document.getElementById('faceStatus').textContent = 'Face not recognized.';
                }
            } else {
                document.getElementById('faceStatus').textContent = 'No face detected.';
            }
        });

        // Eye scan
        document.getElementById('scanEye').addEventListener('click', async () => {
            const detection = await faceapi.detectSingleFace(video).withFaceLandmarks();
            if (detection) {
                const landmarks = detection.landmarks;
                const leftEye = landmarks.getLeftEye();
                const rightEye = landmarks.getRightEye();
                if (leftEye.length > 0 && rightEye.length > 0) {
                    document.getElementById('eyeStatus').textContent = 'Eyes detected! Proceeding to voice.';
                    document.getElementById('eyeStep').style.display = 'none';
                    document.getElementById('voiceStep').style.display = 'block';
                } else {
                    document.getElementById('eyeStatus').textContent = 'Eyes not clearly visible.';
                }
            } else {
                document.getElementById('eyeStatus').textContent = 'No face detected.';
            }
        });

        // Voice recognition
        document.getElementById('startVoice').addEventListener('click', () => {
            const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = 'en-US';
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript.toLowerCase();
                if (transcript.includes(passphrase)) {
                    document.getElementById('voiceStatus').textContent = 'Voice verified! Locker unlocked.';
                    document.getElementById('auth').style.display = 'none';
                    document.getElementById('locker').style.display = 'block';
                } else {
                    document.getElementById('voiceStatus').textContent = 'Incorrect passphrase.';
                }
            };
            recognition.onerror = () => {
                document.getElementById('voiceStatus').textContent = 'Voice recognition error.';
            };
            recognition.start();
        });

        // Init
        loadModels().then(startVideo);
    </script>
</body>
</html>